import time
from typing import Any

from openai import OpenAI
from project.utils.config import Config
import logging

logger = logging.getLogger(__name__)


class OpenAIClient:
    """
    Client to interact with the OpenAI API.

    Attributes:
        config (Config): Configuration object to fetch API keys and settings.
        client (OpenAI): OpenAI client initialized with the API key.
        system_context (str): System content to guide the OpenAI model.
    """

    def __init__(self) -> None:
        """
        Initializes the OpenAIClient with the necessary configurations.
        """
        self.config = Config()
        self.client = OpenAI(api_key=self.config.get_openai_key())
        self.system_context = self.config.get_llm_system_context()
        logger.info("OpenAIClient initialized")

    def _generate_response(self, prompt: str, placeholder: str, text: str, model: str) -> tuple[Any, float]:
        """
        Generates a response using OpenAI API by replacing a placeholder in the prompt with the given text.

        Args:
            prompt (str): The base prompt template.
            placeholder (str): The placeholder text to be replaced.
            text (str): The text to insert into the placeholder.
            model (str): The model to use for generating the response.

        Returns:
            str: The generated response.
        """
        final_prompt = prompt.replace(placeholder, text)
        logger.info(f"Generating text with prompt: {final_prompt}")

        try:
            start_time = time.time()
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": self.system_context},
                    {"role": "user", "content": final_prompt}
                ],
                temperature=0.5,
                max_tokens=1000
            )
            analysis_text = response.choices[0].message.content.strip()
            end_time = time.time()
            elapsed_time = end_time - start_time
            analysis = {
                "model": model,
                "message": {"content": analysis_text}
            }
            return analysis, elapsed_time
        except Exception as e:
            logger.error(f"Error generating response: {e}")
            return "An error occurred while generating the response.", 0

    def analyze_tweets(self, review: str) -> tuple[Any, float]:
        """
        Analyzes the given tweet review by generating a response from the OpenAI API.

        Args:
            review (str): The tweet review to be analyzed.

        Returns:
            str: The response generated by the OpenAI model.
        """
        return self._generate_response(self.config.get_llm_prompt("tweet"), "{text_tweet}", review,
                                       self.config.get_openai_llm())

    def analyze_news(self, review: str) -> tuple[Any, float]:
        """
        Analyzes the given news review by generating a response from the OpenAI API.

        Args:
            review (str): The news review to be analyzed.

        Returns:
            str: The response generated by the OpenAI model.
        """
        return self._generate_response(self.config.get_llm_prompt("notice"), "{text_new}", review,
                                       self.config.get_openai_llm())

    def verify_api_key(self) -> bool:
        """
        Verifies if the provided API key for OpenAI is valid.

        Returns:
            bool: True if the API key is valid, False otherwise.
        """
        try:
            self.client.models.list()
        except:
            return False
        else:
            return True
